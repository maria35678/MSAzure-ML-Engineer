{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transaction = pd.read_csv('test_transaction.csv')\n",
    "test_identity = pd.read_csv('test_identity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_split(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean data and split some useful data from each columns for identity dataset.\n",
    "    Args:\n",
    "        - dataframe : pd.DataFrame\n",
    "    Output:\n",
    "        - dataframe : pd.DataFrame\n",
    "    \"\"\"\n",
    "    dataframe['device_name'] = dataframe['DeviceInfo'].str.split('/', expand=True)[0]\n",
    "    dataframe['device_version'] = dataframe['DeviceInfo'].str.split('/', expand=True)[1]\n",
    "\n",
    "    dataframe['OS_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['browser_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['screen_width'] = dataframe['id_33'].str.split('x', expand=True)[0]\n",
    "    dataframe['screen_height'] = dataframe['id_33'].str.split('x', expand=True)[1]\n",
    "\n",
    "    dataframe['id_34'] = dataframe['id_34'].str.split(':', expand=True)[1]\n",
    "    dataframe['id_23'] = dataframe['id_23'].str.split(':', expand=True)[1]\n",
    "\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n",
    "\n",
    "    dataframe.loc[dataframe.device_name.isin(dataframe.device_name.value_counts()[dataframe.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n",
    "    dataframe['had_id'] = 1    \n",
    "    return dataframe\n",
    "\n",
    "def select_col(dataframe : pd.DataFrame) -> pd.DataFrame:\n",
    "    useful_features = ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1',\n",
    "                   'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13',\n",
    "                   'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M2', 'M3',\n",
    "                   'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V17',\n",
    "                   'V19', 'V20', 'V29', 'V30', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V40', 'V44', 'V45', 'V46', 'V47', 'V48',\n",
    "                   'V49', 'V51', 'V52', 'V53', 'V54', 'V56', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V69', 'V70', 'V71',\n",
    "                   'V72', 'V73', 'V74', 'V75', 'V76', 'V78', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V87', 'V90', 'V91', 'V92',\n",
    "                   'V93', 'V94', 'V95', 'V96', 'V97', 'V99', 'V100', 'V126', 'V127', 'V128', 'V130', 'V131', 'V138', 'V139', 'V140',\n",
    "                   'V143', 'V145', 'V146', 'V147', 'V149', 'V150', 'V151', 'V152', 'V154', 'V156', 'V158', 'V159', 'V160', 'V161',\n",
    "                   'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V169', 'V170', 'V171', 'V172', 'V173', 'V175', 'V176', 'V177',\n",
    "                   'V178', 'V180', 'V182', 'V184', 'V187', 'V188', 'V189', 'V195', 'V197', 'V200', 'V201', 'V202', 'V203', 'V204',\n",
    "                   'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V219', 'V220',\n",
    "                   'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V231', 'V233', 'V234', 'V238', 'V239',\n",
    "                   'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V249', 'V251', 'V253', 'V256', 'V257', 'V258', 'V259', 'V261',\n",
    "                   'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276',\n",
    "                   'V277', 'V278', 'V279', 'V280', 'V282', 'V283', 'V285', 'V287', 'V288', 'V289', 'V291', 'V292', 'V294', 'V303',\n",
    "                   'V304', 'V306', 'V307', 'V308', 'V310', 'V312', 'V313', 'V314', 'V315', 'V317', 'V322', 'V323', 'V324', 'V326',\n",
    "                   'V329', 'V331', 'V332', 'V333', 'V335', 'V336', 'V338', 'id_01', 'id_02', 'id_03', 'id_05', 'id_06', 'id_09',\n",
    "                   'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_17', 'id_19', 'id_20', 'id_30', 'id_31', 'id_32', 'id_33',\n",
    "                   'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'device_name', 'device_version', 'OS_id_30', 'version_id_30',\n",
    "                   'browser_id_31', 'version_id_31', 'screen_width', 'screen_height', 'had_id']\n",
    "\n",
    "    cols_to_drop = [col for col in dataframe.columns if col not in useful_features]\n",
    "    cols_to_drop = [col for col in cols_to_drop if col not in ['isFraud', 'TransactionDT']]\n",
    "    \n",
    "    dataframe = dataframe.drop(cols_to_drop, axis=1)\n",
    "    return dataframe\n",
    "\n",
    "def feature_engineering_one(dataframe : pd.DataFrame) -> pd.DataFrame:\n",
    "    columns_a = ['TransactionAmt', 'id_02', 'D15']\n",
    "    columns_b = ['card1', 'card4', 'addr1']\n",
    "\n",
    "    for col_a in columns_a:\n",
    "        for col_b in columns_b:\n",
    "            for df in [dataframe]:\n",
    "                df[f'{col_a}_to_mean_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('mean')\n",
    "                df[f'{col_a}_to_std_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('std')\n",
    "    \n",
    "    # New feature - log of transaction amount.\n",
    "    dataframe['TransactionAmt_Log'] = np.log(dataframe['TransactionAmt'])\n",
    "    \n",
    "    # New feature - decimal part of the transaction amount.\n",
    "    dataframe['TransactionAmt_decimal'] = ((dataframe['TransactionAmt'] - dataframe['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "\n",
    "    # New feature - day of week in which a transaction happened.\n",
    "    dataframe['Transaction_day_of_week'] = np.floor((dataframe['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "\n",
    "    # New feature - hour of the day in which a transaction happened.\n",
    "    dataframe['Transaction_hour'] = np.floor(dataframe['TransactionDT'] / 3600) % 24\n",
    "\n",
    "    # Some arbitrary features interaction\n",
    "    for feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n",
    "                    'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1']:\n",
    "\n",
    "        f1, f2 = feature.split('__')\n",
    "        dataframe[feature] = dataframe[f1].astype(str) + '_' + dataframe[f2].astype(str)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(dataframe[feature].astype(str).values))\n",
    "        dataframe[feature] = le.transform(list(dataframe[feature].astype(str).values))\n",
    "\n",
    "    # Encoding - count encoding for both train and test\n",
    "    for feature in ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'id_36']:\n",
    "        dataframe[feature + '_count_full'] = dataframe[feature].map(pd.concat([dataframe[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "    # Encoding - count encoding separately for train and test\n",
    "    for feature in ['id_01', 'id_31', 'id_33', 'id_36']:\n",
    "        dataframe[feature + '_count_dist'] = dataframe[feature].map(dataframe[feature].value_counts(dropna=False))\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def feature_engineering_two(dataframe : pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft', \n",
    "    'comcast.net': 'other','yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', 'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', \n",
    "    'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink', 'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', \n",
    "    'gmx.de': 'other', 'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other', 'hotmail.fr': 'microsoft', \n",
    "    'windstream.net': 'other', 'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', 'netzero.net': 'other', \n",
    "    'suddenlink.net': 'other', 'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo', 'msn.com': 'microsoft', \n",
    "    'q.com': 'centurylink', 'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other','rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', \n",
    "    'frontiernet.net': 'yahoo', 'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', \n",
    "    'cableone.net': 'other', 'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', 'yahoo.com': 'yahoo', \n",
    "    'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n",
    "     \n",
    "    us_emails = ['gmail', 'net', 'edu']\n",
    "\n",
    "    for c in ['P_emaildomain', 'R_emaildomain']:\n",
    "        dataframe[c + '_bin'] = dataframe[c].map(emails)\n",
    "        dataframe[c + '_suffix'] = dataframe[c].map(lambda x: str(x).split('.')[-1])\n",
    "        dataframe[c + '_suffix'] = dataframe[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n",
    "\n",
    "\n",
    "    for col in dataframe.columns:\n",
    "        if dataframe[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            le.fit(list(dataframe[col].astype(str).values))\n",
    "            dataframe[col] = le.transform(list(dataframe[col].astype(str).values))\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_identity.columns = [ col_name.replace('-', '_') for col_name in test_identity.columns]\n",
    "\n",
    "test_identity = id_split(test_identity)\n",
    "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_selected = select_col(test)\n",
    "\n",
    "test_model = feature_engineering_one(test_selected)\n",
    "test_model = feature_engineering_two(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_10k = test_model[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL for the web service, should be similar to:\n",
    "# 'http://8530a665-66f3-49c8-a953-b82a2d312917.eastus.azurecontainer.io/score'\n",
    "scoring_uri = 'http://994b56db-a2b8-4245-8e72-08a134c0caec.southeastasia.azurecontainer.io/score'\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "key = '9YQOFsffryPke3pFVp7qWZKA2LZXdm1A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10001):    \n",
    "    data_request = {}\n",
    "    data_request[\"data\"] = test_model_10k[i: i+1].fillna(0).to_dict('records')\n",
    "    # Convert to JSON string\n",
    "    input_data = json.dumps(data_request)\n",
    "    with open(\"data.json\", \"w\") as _f:\n",
    "        _f.write(input_data)\n",
    "    \n",
    "    # Set the content type\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    # If authentication is enabled, set the authorization header\n",
    "    headers['Authorization'] = f'Bearer {key}'\n",
    "    \n",
    "    # Make the request and display the response\n",
    "    resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "    print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
